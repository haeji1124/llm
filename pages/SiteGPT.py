from langchain.document_loaders import SitemapLoader
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.storage import LocalFileStore
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.callbacks.base import BaseCallbackHandler
import streamlit as st
import requests, os


class ChatCallbackHandler(BaseCallbackHandler):
    message = ""

    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        save_message(self.message, "ai")

    def on_llm_new_token(self, token, *args, **kwargs):
        self.message += token
        self.message_box.markdown(self.message)


def is_valid(key):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {key}",
    }
    try:
        response = requests.get(
            "https://api.openai.com/v1/models", headers=headers)
        if response.status_code == 200:
            return True
        else:
            return False
    except:
        return False
    

answers_prompt = ChatPromptTemplate.from_template(
    """
    ë‹¤ìŒì˜ contextë§Œì„ ì´ìš©í•´ì„œ ì§ˆë¬¸ì— ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µí•˜ê³ , ê¾¸ë©°ë‚´ê±°ë‚˜ ê³¼ì¥í•˜ì§€ ë§ˆì„¸ìš”.
    ê° ëŒ€ë‹µì—ëŠ” 0ì—ì„œ 5ê¹Œì§€ì˜ scoreë¥¼ ë¶€ì—¬í•˜ì„¸ìš”.
    ëŒ€ë‹µì´ ì •í™•í•  ìˆ˜ë¡ scoreëŠ” ë†’ì•„ì•¼í•˜ê³ , ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ë¡ scoreëŠ” ë‚®ì•„ì•¼í•©ë‹ˆë‹¤.
    0ì ì´ë¼ê³  í•´ë„ ëŒ€ë‹µì˜ scoreë¥¼ í¬í•¨í•˜ì„¸ìš”.

    Context: {context}

    ì˜ˆì‹œ:

    question: ë‹¬ì€ ì–¼ë§ˆë‚˜ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆë‚˜ìš”?
    answer: ë‹¬ì€ 384,400 km ë–¨ì–´ì ¸ìˆìŠµë‹ˆë‹¤.
    score: 5

    question: íƒœì–‘ì€ ì–¼ë§ˆë‚˜ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆë‚˜ìš”?
    answer: ëª¨ë¦…ë‹ˆë‹¤.
    score: 0

    ì´ì œ ë‹¹ì‹ ì˜ ì°¨ë¡€ì…ë‹ˆë‹¤!

    question: {question}
"""
)


def get_answers(inputs):
    docs = inputs["docs"]
    question = inputs["question"]
    # Map Re Rankì˜ ê³¼ì •ì€ ì¶œë ¥í•˜ì§€ ì•Šê¸° ìœ„í•´ streaming í•˜ì§€ ì•ŠëŠ” llm ì‚¬ìš©
    answers_chain = answers_prompt | llm
    return {
        "question": question,
        "answers": [
            {
                "answer": answers_chain.invoke(
                    {"question": question, "context": doc.page_content}
                ).content,
                "source": doc.metadata["source"],
                "date": doc.metadata["lastmod"],
            }
            for doc in docs
        ],
    }


choose_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            ì•„ë˜ì— ì œì‹œë˜ëŠ” ëŒ€ë‹µë“¤ë§Œì„ ì‚¬ìš©í•´ì„œ ì§ˆë¬¸ì— ìµœì¢…ì ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.
            scoreê°€ ë†’ê³ (ë„ì›€ì´ ë˜ëŠ”) ìµœì‹ ì˜ ëŒ€ë‹µì„ ì‚¬ìš©í•˜ì„¸ìš”.
            ëŒ€ë‹µì˜ ì¶œì²˜ì™€ lastmodë¥¼ ë§ë¶™ì´ë˜, ìˆ˜ì •í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì œì‹œí•˜ì„¸ìš”.

            answers: {answers}
            """,
        ),
        ("human", "{question}"),
    ]
)


def choose_answer(inputs):
    answers = inputs["answers"]
    question = inputs["question"]
    # ìµœì¢… ê²°ê³¼ëŠ” ì¶œë ¥ì„ ìœ„í•´ streaming í•˜ëŠ” llm_streaming ì‚¬ìš©
    choose_chain = choose_prompt | llm_streaming
    condensed = "\n\n".join(
        f"{answer['answer']}\nSource:{answer['source']}\nDate:{answer['date']}\n"
        for answer in answers
    )
    return choose_chain.invoke(
        {
            "question": question,
            "answers": condensed,
        }
    )


def parse_page(soup):
    # Cloudflareì˜ ê²½ìš° <main> íƒœê·¸ì— ì»¨í…ì¸ ê°€ í¬í•¨ë¨
    return (
        str(soup.find("main").get_text())
        .replace("\n", " ")
        .replace("\xa0", " ")
        .replace("Edit page   Cloudflare DashboardDiscordCommunityLearning CenterSupport Portal  Cookie Settings", "")
    )


@st.cache_resource(show_spinner="ì›¹ì‚¬ì´íŠ¸ ë¡œë”© ì¤‘...")
def load_website(url, key):
    # .cache í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±í•´ì¤€ë‹¤.
    file_folder = './.cache/embeddings/site'
    
    if not os.path.exists(file_folder):
        os.makedirs(file_folder)

    cache_dir = LocalFileStore(f"{file_folder}")

    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000,
        chunk_overlap=200,
    )
    loader = SitemapLoader(
        url,
        parsing_function=parse_page,
        # ì•„ë˜ 3ê°œì˜ URLë§Œ ëŒ€ìƒìœ¼ë¡œ í•¨
        filter_urls=[
            'https://developers.cloudflare.com/ai-gateway/',
            'https://developers.cloudflare.com/vectorize/',
            'https://developers.cloudflare.com/workers-ai/',
        ]
    )
    loader.requests_per_second = 2
    docs = loader.load_and_split(text_splitter=splitter)
    embeddings = OpenAIEmbeddings(api_key=key)
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)
    vector_store = FAISS.from_documents(docs, cached_embeddings)
    return vector_store.as_retriever()


def save_message(message, role):
    st.session_state["messages"].append({"message": message, "role": role})


def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)


def paint_history():
    for message in st.session_state["messages"]:
        send_message(
            message["message"],
            message["role"],
            save=False,
        )


st.set_page_config(
    page_title="SiteGPT",
    page_icon="ğŸ–¥ï¸",
)

st.title("ğŸ–¥ï¸ SiteGPT")

st.markdown(
    """
    # SiteGPT
            
    Ask questions about the content of a website.
            
    Start by writing the URL of the website on the sidebar.
"""
)

with st.sidebar:
    # Cloudflareë¥¼ ìœ„í•œ ë¬¸ì„œë¡œ URLì„ ê³ ì •ì‹œí‚´
    url = "https://developers.cloudflare.com/sitemap-0.xml"

    key = st.text_input("OPEN_API_KEY", placeholder="OPENAI_API_KEYë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", type="password")

    if key:
        # OPENAI_API_KEY ê°€ ì…ë ¥ë˜ë©´ íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥
        if is_valid(key):
            st.success("ìœ íš¨í•œ OPENAI_API_KEY ì…ë‹ˆë‹¤.")
            
            # ChatCallbackHandler()ì—ì„œ llmì„ ëª¨ë‹ˆí„°ë§í•˜ë©´ì„œ tokenì„ ì¶”ê°€í•´ì£¼ëŠ”ë°, Map Re Rankì˜ ì¤‘ê°„ê³¼ì •ì€ ì¶œë ¥í•´ì£¼ê³  ì‹¶ì§€ ì•Šì•˜ìŒ
            # ë”°ë¼ì„œ, llmì„ 2ê°œë¡œ ë¶„ë¦¬í•˜ì—¬, get_answers()ëŠ” streamingì„ í•˜ì§€ ì•Šê³ , choose_answerëŠ” streaming ì²˜ë¦¬
            llm = ChatOpenAI(
                temperature=0.1,
                model="gpt-4o-mini-2024-07-18",
                # streaming=True,
                # callbacks=[ChatCallbackHandler(),],
                api_key=key
            )

            llm_streaming = ChatOpenAI(
                temperature=0.1,
                model="gpt-4o-mini-2024-07-18",
                streaming=True,
                callbacks=[ChatCallbackHandler(),],
                api_key=key
            )

            ############ ì—¬ê¸°ì„œëŠ” URLì„ ê³ ì •ì‹œì¼°ìœ¼ë¯€ë¡œ, URL ì…ë ¥ ë¶€ë¶„ì€ ì£¼ì„ ì²˜ë¦¬
            # url = st.text_input(
            #     "URLì„ ì…ë ¥í•˜ì„¸ìš”.", "",
            #     placeholder="https://example.com",
            # )
        else:
            st.warning("ì˜¬ë°”ë¥¸ OPENAI_API_KEYë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            key = ""

if key:
    ############ URLì˜ êµ¬ì¡° íŒŒì•… ë° parsingì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œ
    # if url:
    #     loader = SitemapLoader(url,
    #         parsing_function=parse_page,
    #         filter_urls=[
    #             'https://developers.cloudflare.com/ai-gateway/',
    #             'https://developers.cloudflare.com/vectorize/',
    #             'https://developers.cloudflare.com/workers-ai/',
    #         ]
    #     )
    #     loader.requests_per_second = 1
    #     docs = loader.load()
    #     st.write(docs)

    ############ ì—¬ê¸°ì„œëŠ” URLì„ ê³ ì •ì‹œì¼°ìœ¼ë¯€ë¡œ, Sitemap URL ì—¬ë¶€ë¥¼ ì²´í¬í•˜ëŠ” ë¶€ë¶„ì€ ì£¼ì„ ì²˜ë¦¬
    # if ".xml" not in url:
    #     with st.sidebar:
    #         st.error("Sitemap URLë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
    # else:
    retriever = load_website(url, key)

    send_message("Hi", "ai", save=False)
    paint_history()
    message = st.chat_input("please ask about document")
    if message:
        send_message(message, "human")
        chain = (
            {
                "docs": retriever,
                "question": RunnablePassthrough(),
            }
            | RunnableLambda(get_answers)
            | RunnableLambda(choose_answer)
        )
        with st.chat_message("ai"):
            chain.invoke(message).content.replace("$", "\$")
else:
    st.session_state["messages"] = []